{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79351d3-c323-4d4c-a41f-9d7ebd8c317e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d995a-14bd-486b-9b92-28aaedf4be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.integrate import odeint\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from torch import nn, autograd\n",
    "from src.transformer_nn import TransformerModel\n",
    "#from src.transformer_nn import SimpleLinearModel\n",
    "from src.duffing_generator_batch import DuffingGeneratorClass\n",
    "from src.physics_loss import physics_loss_class\n",
    "import torch.optim as op \n",
    "%load_ext jupyter_ai\n",
    "import torch.optim as optim\n",
    "#from torch.utils.data import Data\n",
    "import transformers #import Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02c230-6034-4bd0-b397-8e369c72ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 1, 1000).view(-1, 1)\n",
    "dg = DuffingGeneratorClass()  # Instantiate your class\n",
    "\n",
    "device = 'cuda'\n",
    "torch.manual_seed(123)\n",
    "physics_loss_instance = physics_loss_class()\n",
    "# Set up the physics loss training locations\n",
    "x_physics = torch.linspace(0, 1, 15).view(-1, 1).requires_grad_(True)\n",
    "X_BOUNDARY = 0.0  # Example value, adjust as needed\n",
    "F_BOUNDARY = 0.0  # Example value, adjust as needed\n",
    "N_INPUT= 6 #(or more, depending on your features)\n",
    "N_OUTPUT= 1 #(or the number of features you want to predict)\n",
    "N_HIDDEN= 256 # or 256\n",
    "N_LAYERS= 4 #to 4\n",
    "N_HEADS= 8 #or 8 (should divide evenly into N_HIDDEN)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = TransformerModel(N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS, N_HEADS).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_instance = physics_loss_class()\n",
    "\n",
    "num_epochs = 10  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d8885-d478-424a-bff0-389165c23c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Create a small batch of test data with varying time\n",
    "test_time = torch.linspace(0, 1, 10).view(-1, 1)  # 10 time steps\n",
    "test_params = torch.zeros(10, 5)  # Keep other parameters constant\n",
    "test_x_combined = torch.cat((test_time, test_params), dim=1).to(device)\n",
    "\n",
    "# Get model's predictions for this test data\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_output = model(test_x_combined)\n",
    "    print(\"Model output for test data:\", test_output)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4e330-214b-4833-9af9-ae0703c57d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(dg.duffing_generator()):\n",
    "        x_combined, y_batch = batch\n",
    "        x_combined, y_batch = x_combined.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_combined)\n",
    "        \n",
    "        # Compute physics loss\n",
    "        loss_physics = loss_instance.physics_loss(model, batch, x_combined, y_batch)\n",
    "        \n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = loss_physics \n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Optionally print or log the loss\n",
    "        print(f\"Batch {batch_idx}, Total Loss: {total_loss.item()}\")\n",
    "\n",
    "    # Visualization every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            yh = model(x_combined).detach().cpu().numpy()\n",
    "            time_points = x_combined[:, 0].cpu().numpy()  # Extract time points from combined input\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(time_points, y_batch.cpu().numpy(), label='Ground Truth')\n",
    "            plt.plot(time_points, yh, label='Neural Network Output')\n",
    "            plt.scatter(time_points, y_batch.cpu().numpy(), color='red', label='Training Points')\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Value\")\n",
    "            plt.legend()\n",
    "            plt.title(f\"Model Output vs Ground Truth at Epoch {epoch+1}\")\n",
    "            plt.show()\n",
    "\n",
    "    # Optional: Add validation logic here\n",
    "\n",
    "# Optional: Save the model after training\n",
    "# torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bc8b9-2944-4f9d-bf9f-edff45b5c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40799d56-f7cf-4dc0-b80f-ce38f287d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions or use actual test data for test_input\n",
    "test_input_dimensions = (100, 6)  # Example dimensions, modify as necessary\n",
    "test_input = torch.randn(test_input_dimensions, dtype=torch.double, requires_grad=True)  # Create a random tensor with requires_grad set to True\n",
    "\n",
    "# Convert test input to Float\n",
    "test_input = test_input.float()\n",
    "\n",
    "# Move model and test_input to the same device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "test_input = test_input.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test function for gradcheck\n",
    "def test_func(input):\n",
    "    return model(input)\n",
    "# Perform the gradcheck with the modified test input\n",
    "gradcheck_passed = gradcheck(test_func, test_input, eps=1e-5, atol=1e-4)\n",
    "print(\"Gradcheck passed:\", gradcheck_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8aa14-0cb3-46b5-abdd-13f7952877ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a sample input tensor with batch size greater than 1\n",
    "sample_input = torch.randn(2, N_INPUT, requires_grad=True)\n",
    "\n",
    "# Move model and sample_input to the same device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "sample_input = sample_input.to(device)\n",
    "\n",
    "# Forward pass\n",
    "output = model(sample_input)\n",
    "\n",
    "# Sample loss computation (replace with a loss appropriate for your model)\n",
    "sample_loss = output.sum()\n",
    "\n",
    "# Backward pass\n",
    "sample_loss.backward()\n",
    "\n",
    "# Check if gradients are computed for the input\n",
    "print(\"Gradients for the input tensor:\", sample_input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5951d-d23e-4e2a-a5e1-78b2205df0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
