{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5d995a-14bd-486b-9b92-28aaedf4be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.integrate import odeint\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from torch import nn, autograd\n",
    "from src.fcn import FullyConnectedNet\n",
    "from src.fcn import FullyConnectedNetTanh\n",
    "from src.fcn import CustomFCN\n",
    "from src.fcn import FCN\n",
    "from src.transformer_nn import TransformerModel\n",
    "#from src.transformer_nn import SimpleLinearModel\n",
    "from src.duffing_generator import DuffingGeneratorClass\n",
    "from src.physics_loss import physics_loss_class\n",
    "import torch.optim as op \n",
    "%load_ext jupyter_ai\n",
    "import torch.optim as optim\n",
    "#from torch.utils.data import Data\n",
    "import transformers #import Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f191478-96f9-4101-9ef9-faf72c02e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example initialization\n",
    "n_param_features = 5  # Number of parameter features\n",
    "n_time_features = 1  # Number of time features\n",
    "total_features = 6\n",
    "n_hidden = 64  # Number of hidden units\n",
    "n_layers = 128 # Number of layers\n",
    "torch.manual_seed(123)\n",
    "#model = CustomFCN(num_parameters, n_hidden, n_layers)\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = FullyConnectedNetTanh( n_time_features, n_param_features, n_hidden, n_layers)\n",
    "#model = FCN(N_INPUT=5, N_OUTPUT=1, N_HIDDEN=5, N_LAYERS=2)\n",
    "#model = TransformerModel(n_time_features, n_param_features, n_hidden, n_layers, n_heads).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_instance = physics_loss_class()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4e330-214b-4833-9af9-ae0703c57d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: torch.Size([500, 1])\n",
      "Shape of y_physics: torch.Size([32, 500, 1])\n",
      "Batch 0, Total Loss: 0.06744920462369919\n",
      "Batch 1, Total Loss: 0.37555983662605286\n",
      "Batch 2, Total Loss: 0.006547011435031891\n",
      "Batch 3, Total Loss: 0.02405976876616478\n",
      "Batch 4, Total Loss: 0.07563720643520355\n",
      "Batch 5, Total Loss: 0.05963421240448952\n",
      "Batch 6, Total Loss: 0.003828533226624131\n",
      "Batch 7, Total Loss: 0.017194554209709167\n",
      "Batch 8, Total Loss: 0.09736523777246475\n",
      "Batch 9, Total Loss: 0.010010618716478348\n",
      "Batch 10, Total Loss: 0.043895430862903595\n",
      "Batch 11, Total Loss: 0.019674237817525864\n",
      "Batch 12, Total Loss: 0.26429611444473267\n",
      "Batch 13, Total Loss: 0.18496675789356232\n",
      "Batch 14, Total Loss: 0.005545433145016432\n",
      "Batch 15, Total Loss: 0.06932432949542999\n",
      "Batch 16, Total Loss: 0.05111588165163994\n",
      "Batch 17, Total Loss: 0.12501160800457\n",
      "Batch 18, Total Loss: 0.3641182482242584\n",
      "Batch 19, Total Loss: 0.00864371657371521\n",
      "Batch 20, Total Loss: 0.0515361949801445\n",
      "Batch 21, Total Loss: 0.017836183309555054\n",
      "Batch 22, Total Loss: 0.060834530740976334\n",
      "Batch 23, Total Loss: 0.40018945932388306\n",
      "Batch 24, Total Loss: 0.11070115864276886\n"
     ]
    }
   ],
   "source": [
    "dg = DuffingGeneratorClass()\n",
    "X = torch.linspace(0, 1, 500)  # Time vector\n",
    "physics_loss_instance = physics_loss_class()\n",
    "# Set up the physics loss training locations\n",
    "x_physics = torch.linspace(0, 1, 500).view(-1, 1).requires_grad_(True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the global time tensor X (ensure it's of appropriate shape and on the correct device)\n",
    "X= X.to(device)  # Example: torch.linspace(0, 10, steps=1000).view(-1, 1)\n",
    "\n",
    "# Boundary and other problem-specific configurations\n",
    "X_BOUNDARY = 0  # Define boundary conditions\n",
    "F_BOUNDARY = 0  # Define boundary function/values\n",
    "num_epochs = 1000  # Number of epochs to train\n",
    "num_batches = torch.tensor(32)  # Number of batches\n",
    "N = 20 # Number of times to feed each unique set of parameters and X into the model\n",
    "boundary_loss_weight = 1  # Adjust as necessary\n",
    "# Set random seed for reproducibility\n",
    "X = X.view(-1, 1)  # or X.unsqueeze(1)\n",
    "torch.manual_seed(123)\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_epoch_loss = 0  # To accumulate loss over the epoch\n",
    "\n",
    "    # Generate data for all batches\n",
    "    params, y_physics = dg.duffing_generator_batch(num_batches.item(), X)\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y_physics:\", y_physics.shape)\n",
    "    \n",
    "    # Transfer the entire dataset to the device at once\n",
    "    params, y_physics = params.to(device), y_physics.to(device)\n",
    "    \n",
    "    for idx in range(num_batches.item()):\n",
    "        optimizer.zero_grad()\n",
    "        total_batch_loss = 0  # To accumulate loss over the batch for N iterations\n",
    "\n",
    "        for _ in range(N):\n",
    "            # Accessing parameters and y_physics for the current batch\n",
    "            current_params = params[idx]  # No need to unsqueeze here as we have a clear batch dimension\n",
    "            current_y_physics = y_physics[idx]\n",
    "\n",
    "            # Create the combined input tensor for the current batch\n",
    "            #combined_input = torch.cat((X, current_params), dim=1)\n",
    "\n",
    "            # Selecting a subset of the combined input and corresponding y_physics data\n",
    "           # x_params_data = combined_input[0:200:20]\n",
    "            y_data = current_y_physics[0:400:2]\n",
    "\n",
    "            # Forward pass: compute predicted y by passing x_params_data to the model\n",
    "            y_pred = model(current_params[0:400:2],X[0:400:2])#.squeeze()  # Ensure dimensions match\n",
    "            \n",
    "            # Compute physics loss\n",
    "            mse_loss = torch.mean((y_pred - y_data) ** 2)\n",
    "\n",
    "            # Replicate x_boundary to match the size of X or current_params\n",
    "            x_boundary = torch.tensor([X_BOUNDARY], device=device, dtype=torch.float).repeat(X.size(0), 1).requires_grad_(True)\n",
    "            f_boundary = torch.tensor([F_BOUNDARY], device=device, dtype=torch.float).repeat(X.size(0), 1)\n",
    "            \n",
    "            # Now, x_boundary has the same size in dim 0 as current_params, allowing concatenation\n",
    "            boundary_input = torch.cat((x_boundary, current_params), dim=1)\n",
    "            \n",
    "            # Proceed with model prediction and loss calculation\n",
    "            yh_boundary = model(x_boundary, current_params)\n",
    "            loss_boundary = torch.mean((yh_boundary - f_boundary) ** 2)\n",
    "            # Compute physics loss\n",
    "            loss_physics = physics_loss_instance.physics_loss(model, current_params,X)\n",
    "\n",
    "            # Combine losses\n",
    "            total_loss = mse_loss + boundary_loss_weight * loss_boundary + loss_physics\n",
    "          \n",
    "\n",
    "            # Backpropagation\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  # Clear gradients for the next mini-batches\n",
    "            \n",
    "            total_batch_loss += total_loss.item()\n",
    "\n",
    "        # Accumulate epoch loss\n",
    "        total_epoch_loss += total_batch_loss / N  # Average loss per batch\n",
    "    # Log or print epoch-wise total loss here if desired\n",
    "        print(f\"Batch {idx}, Total Loss: {total_loss.item()}\")\n",
    "    # Logging\n",
    "    print(f\"Epoch {epoch+1}, Total Loss: {total_epoch_loss}\")\n",
    "\n",
    "    # Adjust learning rate based on scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "      # Visualization every epoch\n",
    "    if (epoch+1) % 1 == 0:   \n",
    "        yh = model(x_boundary, current_params).detach().numpy()\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(X.cpu().numpy(), y_physics[idx].cpu().numpy(), label='Ground Truth')\n",
    "        plt.plot(X.cpu().numpy(), yh, label='Neural Network Output')\n",
    "        plt.scatter(X[0:400:2], y_physics[idx][0:400:2].numpy(), color='red', label='Training points')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "  \n",
    " \n",
    "    # Optional: Add validation logic here\n",
    "\n",
    "# Optional: Save the model after training\n",
    "# torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bc8b9-2944-4f9d-bf9f-edff45b5c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5951d-d23e-4e2a-a5e1-78b2205df0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "# Example correction for indexing issue\n",
    "\n",
    "    for idx, (params, y_physics) in enumerate(zip(*dg.duffing_generator_batch(num_batches, x))):\n",
    "        # Ensure params and y_physics are on the correct device\n",
    "        params, y_physics = params.to(device), y_physics.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Corrected indexing logic here\n",
    "        # Ensure indices are within the bounds of x's size\n",
    "        # This might involve revising how you generate or use indices\n",
    "        \n",
    "        # Correct the sampling logic to match the unexpanded size of x\n",
    "        indices_corrected = torch.arange(0, x.size(0), step).long()  # Adjust step as needed\n",
    "        \n",
    "        # Use the corrected indices to sample from x\n",
    "        x_sampled = x[indices_corrected].to(device)  # Ensure this matches the expected model input size\n",
    "        \n",
    "\n",
    "        indices = torch.arange(0, params.shape[0], step).long()\n",
    "        params_sampled = params[indices]\n",
    "        y_physics_sampled = y_physics[indices]\n",
    "        # Use the corrected indices to sample from x\n",
    "        x_sampled = x[indices_corrected].to(device)\n",
    "        # Then use x_sampled in the model prediction instead of x[indices].to(device)\n",
    "        y_pred = model(x_sampled, params_sampled)\n",
    "        mse_loss = torch.mean((y_pred - y_physics_sampled) ** 2)\n",
    "\n",
    "        # Compute physics loss here if applicable\n",
    "        # Assume `physics_loss` is a function or part of `model` that calculates the physics-based loss\n",
    "        # This step will depend on the specifics of your model and physics loss calculation\n",
    "        physics_loss = physics_loss_function(model, x[indices].to(device), params_sampled)\n",
    "\n",
    "        total_loss = mse_loss + boundary_loss_weight * physics_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Batch {idx}, Total Loss: {total_loss.item()}\")\n",
    "\n",
    "    \n",
    "           # Example print statement (you might have your own logging)\n",
    "        print(f\"Batch {idx}, Total Loss: {total_loss}\")\n",
    "          # Visualization every few epochs (e.g., every 2 epochs)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            yh_full = model(x,params).cpu().numpy()  # Predicted values\n",
    "      \n",
    "\n",
    "            # Assuming 'y_true_full' is the ground truth corresponding to 'x_full'\n",
    "            # You need to adjust this to match how your actual ground truth data is obtained\n",
    "            y_true_full = y_physics  # Placeholder, replace with actual ground truth data\n",
    "\n",
    "            # Plotting,\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(x, y_true_full, label='Ground Truth', linestyle='--')\n",
    "            plt.plot(x, yh_full, label='Neural Network Output')\n",
    "            plt.scatter(x_data.numpy(), y_data.numpy(), color='red', label='Training points')  # Adjust as needed\n",
    "            plt.legend()\n",
    "            plt.title(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
