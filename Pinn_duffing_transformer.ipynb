{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d5d995a-14bd-486b-9b92-28aaedf4be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.integrate import odeint\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from torch import nn, autograd\n",
    "from src.fcn import FullyConnectedNet\n",
    "from src.fcn import FullyConnectedNetTanh\n",
    "from src.fcn import AdaptedFCN\n",
    "from src.fcn import FCN\n",
    "from src.transformer_nn import TransformerModel\n",
    "#from src.transformer_nn import SimpleLinearModel\n",
    "from src.duffing_generator import DuffingGeneratorClass\n",
    "from src.physics_loss import physics_loss_class\n",
    "import torch.optim as op \n",
    "%load_ext jupyter_ai\n",
    "import torch.optim as optim\n",
    "#from torch.utils.data import Data\n",
    "import transformers #import Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f191478-96f9-4101-9ef9-faf72c02e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example initialization\n",
    "n_param_features = 5  # Number of parameter features\n",
    "n_time_features = 1  # Number of time features\n",
    "total_features = 6\n",
    "n_hidden = 512# Number of hidden units\n",
    "n_layers =  32# Number of layers\n",
    "torch.manual_seed(123)\n",
    "#model = CustomFCN(num_parameters, n_hidden, n_layers)\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = AdaptedFCN( n_time_features, n_param_features, n_hidden, n_layers)\n",
    "#model = FCN(N_INPUT=5, N_OUTPUT=1, N_HIDDEN=5, N_LAYERS=2)\n",
    "#model = TransformerModel(n_time_features, n_param_features, n_hidden, n_layers, n_heads).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "loss_instance = physics_loss_class()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d4e330-214b-4833-9af9-ae0703c57d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Total Loss: 0.5786083340644836\n",
      "Batch 1, Total Loss: 1.1689380407333374\n",
      "Batch 2, Total Loss: 0.28034260869026184\n",
      "Batch 3, Total Loss: 0.1450996994972229\n",
      "Batch 4, Total Loss: 0.32347190380096436\n",
      "Batch 5, Total Loss: 0.007255782373249531\n",
      "Batch 6, Total Loss: 0.008512512780725956\n",
      "Batch 7, Total Loss: 0.012564252130687237\n",
      "Batch 8, Total Loss: 0.9804825186729431\n",
      "Batch 9, Total Loss: 0.19756321609020233\n",
      "Batch 10, Total Loss: 0.09484774619340897\n",
      "Batch 11, Total Loss: 0.3619838058948517\n",
      "Batch 12, Total Loss: 1.4325042963027954\n",
      "Batch 13, Total Loss: 0.003104809671640396\n",
      "Batch 14, Total Loss: 0.0804370865225792\n",
      "Batch 15, Total Loss: 0.0312265083193779\n",
      "Batch 16, Total Loss: 0.19462531805038452\n",
      "Batch 17, Total Loss: 0.008869185112416744\n",
      "Batch 18, Total Loss: 0.37839561700820923\n",
      "Batch 19, Total Loss: 0.06317097693681717\n",
      "Batch 20, Total Loss: 0.009518800303339958\n",
      "Batch 21, Total Loss: 0.44158491492271423\n",
      "Batch 22, Total Loss: 0.003976638428866863\n",
      "Batch 23, Total Loss: 0.05375177785754204\n",
      "Batch 24, Total Loss: 0.01123305968940258\n",
      "Batch 25, Total Loss: 0.4126332104206085\n",
      "Batch 26, Total Loss: 0.0637264996767044\n",
      "Batch 27, Total Loss: 0.23197636008262634\n",
      "Batch 28, Total Loss: 0.3324600160121918\n",
      "Batch 29, Total Loss: 0.012122463434934616\n",
      "Batch 30, Total Loss: 0.08015064895153046\n",
      "Batch 31, Total Loss: 0.0036134307738393545\n",
      "Batch 32, Total Loss: 0.003180823754519224\n",
      "Batch 33, Total Loss: 0.43690600991249084\n",
      "Batch 34, Total Loss: 0.1580575406551361\n",
      "Batch 35, Total Loss: 0.040716588497161865\n",
      "Batch 36, Total Loss: 0.271103173494339\n",
      "Batch 37, Total Loss: 0.04455376788973808\n",
      "Batch 38, Total Loss: 0.6639401912689209\n",
      "Batch 39, Total Loss: 0.0043384055607020855\n",
      "Batch 40, Total Loss: 0.07192129641771317\n",
      "Batch 41, Total Loss: 0.11855736374855042\n",
      "Batch 42, Total Loss: 0.009311795234680176\n",
      "Batch 43, Total Loss: 0.20710302889347076\n",
      "Batch 44, Total Loss: 0.022292472422122955\n",
      "Batch 45, Total Loss: 0.2374461442232132\n",
      "Batch 46, Total Loss: 0.5037136077880859\n",
      "Batch 47, Total Loss: 0.4380679130554199\n",
      "Batch 48, Total Loss: 0.0901663601398468\n",
      "Batch 49, Total Loss: 0.10170003026723862\n",
      "Batch 50, Total Loss: 0.151849627494812\n",
      "Batch 51, Total Loss: 0.052996426820755005\n",
      "Batch 52, Total Loss: 0.15298829972743988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 82\u001b[0m\n\u001b[1;32m     78\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m mse_loss  \u001b[38;5;241m+\u001b[39m loss_physics \u001b[38;5;241m+\u001b[39m boundary_loss_weight \u001b[38;5;241m*\u001b[39m loss_boundary\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     84\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear gradients for the next mini-batches\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dg = DuffingGeneratorClass()\n",
    "X = torch.linspace(0, 5, 2500)  # Time vector\n",
    "physics_loss_instance = physics_loss_class()\n",
    "# Set up the physics loss training locations\n",
    "x_physics = torch.linspace(0, 5, 150).view(-1, 1).requires_grad_(True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the global time tensor X (ensure it's of appropriate shape and on the correct device)\n",
    "X= X.to(device)  # Example: torch.linspace(0, 10, steps=1000).view(-1, 1)\n",
    "x_physics = x_physics.to(device)\n",
    "# Boundary and other problem-specific configurations\n",
    "X_BOUNDARY = 0  # Define boundary conditions\n",
    "F_BOUNDARY = 0  # Define boundary function/values\n",
    "num_epochs = 10000  # Number of epochs to train\n",
    "num_batches = torch.tensor(64)  # Number of batches\n",
    "N = 1 # Number of times to feed each unique set of parameters and X into the model\n",
    "boundary_loss_weight = 1  # Adjust as necessary\n",
    "# Set random seed for reproducibility\n",
    "X = X.view(-1, 1)  # or X.unsqueeze(1)\n",
    "torch.manual_seed(123)\n",
    "#device = 'uda'\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_epoch_loss = 0  # To accumulate loss over the epoch\n",
    "\n",
    "    # Generate data for all batches\n",
    "    params, y_physics = dg.duffing_generator_batch(num_batches.item(), X)\n",
    "    #print(\"Shape of X:\", X.shape)\n",
    "    #print(\"Shape of y_physics:\", y_physics.shape)\n",
    "    \n",
    "    # Transfer the entire dataset to the device at once\n",
    "    params, y_physics = params.to(device), y_physics.to(device)\n",
    "    \n",
    "    for idx in range(num_batches.item()):\n",
    "        optimizer.zero_grad()\n",
    "        total_batch_loss = 0  # To accumulate loss over the batch for N iterations\n",
    "\n",
    "        for _ in range(N):\n",
    "            # Accessing parameters and y_physics for the current batch\n",
    "            current_params = params[idx]  # No need to unsqueeze here as we have a clear batch dimension\n",
    "            current_y_physics = y_physics[idx]\n",
    "\n",
    "            # Create the combined input tensor for the current batch\n",
    "            #combined_input = torch.cat((X, current_params), dim=1)\n",
    "\n",
    "            # Selecting a subset of the combined input and corresponding y_physics data\n",
    "           # x_params_data = combined_input[0:200:20]\n",
    "            y_data = current_y_physics[:1000]\n",
    "\n",
    "            # Forward pass: compute predicted y by passing x_params_data to the model\n",
    "            y_pred = model(X[:1000],current_params[:1000])#.squeeze()  # Ensure dimensions match\n",
    "            \n",
    "            # Compute physics loss\n",
    "            mse_loss = torch.mean((y_pred - y_data) ** 2)\n",
    "\n",
    "            # Replicate x_boundary to match the size of X or current_params\n",
    "            x_boundary = torch.tensor([X_BOUNDARY], device=device, dtype=torch.float).repeat(X.size(0), 1).requires_grad_(True)\n",
    "            f_boundary = torch.tensor([F_BOUNDARY], device=device, dtype=torch.float).repeat(X.size(0), 1)\n",
    "            \n",
    "            # Now, x_boundary has the same size in dim 0 as current_params, allowing concatenation\n",
    "            boundary_input = torch.cat((x_boundary, current_params), dim=1)\n",
    "            \n",
    "            # Proceed with model prediction and loss calculation\n",
    "            yh_boundary = model(x_boundary, current_params)\n",
    "            loss_boundary = torch.mean((yh_boundary - f_boundary) ** 2)\n",
    "            #print(\"Shape of x_physics:\", x_physics.shape)\n",
    "            \n",
    "            # Slice current_params to fit the size of x_physics dynamically\n",
    "            params_physics = current_params[:x_physics.size(0), :]\n",
    "            params_physics.requires_grad_(True)  # Set requires_grad to True\n",
    "            #print(\"Shape of params_physics:\", params_physics.shape)\n",
    "            # Compute physics loss\n",
    "            loss_physics = physics_loss_instance.physics_loss(model, params_physics,x_physics)\n",
    "\n",
    "            # Combine losses\n",
    "            total_loss = mse_loss  + loss_physics + boundary_loss_weight * loss_boundary\n",
    "          \n",
    "\n",
    "            # Backpropagation\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  # Clear gradients for the next mini-batches\n",
    "            \n",
    "            total_batch_loss += total_loss.item()\n",
    "\n",
    "        # Accumulate epoch loss\n",
    "        total_epoch_loss += total_batch_loss / N  # Average loss per batch\n",
    "    # Log or print epoch-wise total loss here if desired\n",
    "        print(f\"Batch {idx}, Total Loss: {total_loss.item()}\")\n",
    "    # Logging\n",
    "    print(f\"Epoch {epoch+1}, Total Loss: {total_epoch_loss}\")\n",
    "\n",
    "    # Adjust learning rate based on scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "      # Visualization every epoch\n",
    "    if (epoch+1) % 1 == 0:   \n",
    "        yh = model(x_boundary, current_params).cpu().detach().numpy()\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(X.cpu().numpy(), y_physics[idx].cpu().numpy(), label='Ground Truth')\n",
    "        plt.plot(X.cpu().numpy(), yh, label='Neural Network Output')\n",
    "        plt.scatter(X[:1000].cpu(), y_physics[idx][:1000].cpu().numpy(), color='red', label='Training points')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "  \n",
    " \n",
    "    # Optional: Add validation logic here\n",
    "\n",
    "# Optional: Save the model after training\n",
    "# torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f62bc8b9-2944-4f9d-bf9f-edff45b5c985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5951d-d23e-4e2a-a5e1-78b2205df0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "# Example correction for indexing issue\n",
    "\n",
    "    for idx, (params, y_physics) in enumerate(zip(*dg.duffing_generator_batch(num_batches, x))):\n",
    "        # Ensure params and y_physics are on the correct device\n",
    "        params, y_physics = params.to(device), y_physics.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Corrected indexing logic here\n",
    "        # Ensure indices are within the bounds of x's size\n",
    "        # This might involve revising how you generate or use indices\n",
    "        \n",
    "        # Correct the sampling logic to match the unexpanded size of x\n",
    "        indices_corrected = torch.arange(0, x.size(0), step).long()  # Adjust step as needed\n",
    "        \n",
    "        # Use the corrected indices to sample from x\n",
    "        x_sampled = x[indices_corrected].to(device)  # Ensure this matches the expected model input size\n",
    "        \n",
    "\n",
    "        indices = torch.arange(0, params.shape[0], step).long()\n",
    "        params_sampled = params[indices]\n",
    "        y_physics_sampled = y_physics[indices]\n",
    "        # Use the corrected indices to sample from x\n",
    "        x_sampled = x[indices_corrected].to(device)\n",
    "        # Then use x_sampled in the model prediction instead of x[indices].to(device)\n",
    "        y_pred = model(x_sampled, params_sampled)\n",
    "        mse_loss = torch.mean((y_pred - y_physics_sampled) ** 2)\n",
    "\n",
    "        # Compute physics loss here if applicable\n",
    "        # Assume `physics_loss` is a function or part of `model` that calculates the physics-based loss\n",
    "        # This step will depend on the specifics of your model and physics loss calculation\n",
    "        physics_loss = physics_loss_function(model, x[indices].to(device), params_sampled)\n",
    "\n",
    "        total_loss = mse_loss + boundary_loss_weight * physics_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Batch {idx}, Total Loss: {total_loss.item()}\")\n",
    "\n",
    "    \n",
    "           # Example print statement (you might have your own logging)\n",
    "        print(f\"Batch {idx}, Total Loss: {total_loss}\")\n",
    "          # Visualization every few epochs (e.g., every 2 epochs)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            yh_full = model(x,params).cpu().numpy()  # Predicted values\n",
    "      \n",
    "\n",
    "            # Assuming 'y_true_full' is the ground truth corresponding to 'x_full'\n",
    "            # You need to adjust this to match how your actual ground truth data is obtained\n",
    "            y_true_full = y_physics  # Placeholder, replace with actual ground truth data\n",
    "\n",
    "            # Plotting,\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(x, y_true_full, label='Ground Truth', linestyle='--')\n",
    "            plt.plot(x, yh_full, label='Neural Network Output')\n",
    "            plt.scatter(x_data.numpy(), y_data.numpy(), color='red', label='Training points')  # Adjust as needed\n",
    "            plt.legend()\n",
    "            plt.title(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9221e50-08b1-4c20-9356-f8ebffc92dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
