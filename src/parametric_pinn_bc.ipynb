{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95fe04c0-8d64-4c65-aca6-c18604e7173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.integrate import odeint\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from torch import nn, autograd\n",
    "import random\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ced1cd4-61aa-42fc-acc8-e50bdd492f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/envs/thesis/lib/python3.11/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Define the device globally\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f97bce-1731-4698-bffb-5481e09ddff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(x, y_tensor_squeezed, x_data, y_data, yh, xp=None, physics_params=None, model=None):\n",
    "    \"\"\"\n",
    "    Plots training data, ground truth, model predictions, and optionally physics predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - x: The full range of x values for ground truth data.\n",
    "    - y_tensor_squeezed: Ground truth data corresponding to x.\n",
    "    - x_data: X values of the training data.\n",
    "    - y_data: Y values of the training data (observed outputs).\n",
    "    - yh: Model predictions corresponding to x_data.\n",
    "    - xp: Optional, additional x points for physics-based predictions.\n",
    "    - physics_params: Optional, physics parameters for model if physics predictions are desired.\n",
    "    - model: The trained model, required if physics_params and xp are provided.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot training data\n",
    "    plt.scatter(x_data.detach().numpy(), y_data.detach().numpy(), color=\"tab:orange\", label=\"Training data\")\n",
    "    \n",
    "    # Plot ground truth data\n",
    "    plt.plot(x.detach().numpy(), y_tensor_squeezed.detach().numpy(), 'r-', label='Ground Truth Data')\n",
    "    \n",
    "    # Plot model predictions\n",
    "    plt.plot(x_data.detach().numpy(), yh.detach().numpy(), 'b--', label='Model Predictions')\n",
    "    \n",
    "    # Optionally, plot physics-based predictions\n",
    "    if xp is not None and physics_params is not None and model is not None:\n",
    "        # Assuming model can directly use xp and physics_params for prediction\n",
    "        # You might need to adjust this call based on how your model uses physics_params\n",
    "        yhp = model(torch.cat((xp, torch.tensor(physics_params).repeat(len(xp), 1)), dim=1)).detach()\n",
    "        plt.plot(xp.detach().numpy(), yhp.numpy(), 'g:', label='Physics Predictions')\n",
    "    \n",
    "    plt.xlabel('X Value')\n",
    "    plt.ylabel('Y Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d98d9a-9f3e-4b9b-9499-ccfc40abe823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OscillationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets):#, boundary_conditions\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        #self.boundary_conditions = boundary_conditions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        #boundary_condition = self.boundary_conditions[idx]\n",
    "        return sample, target#, boundary_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a2a7a2-ae3c-4324-97ac-f3067e4b2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_with_boundaries(num_samples, x):\n",
    "    data = []\n",
    "    #boundary_values = []\n",
    "    f_boundary_values = []  # This might be used differently, depending on what exactly you need\n",
    "    \n",
    "    # Ensure x is a numpy array for compatibility with odeint\n",
    "    x_np = x.numpy() if isinstance(x, torch.Tensor) else x\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Randomly choose parameters for each sample\n",
    "        a = random.uniform(-2, 2)\n",
    "        b = random.uniform(0, 3)\n",
    "        d = random.uniform(0, 0.5)\n",
    "        gamma = random.uniform(0, 1.5)\n",
    "        omega = random.uniform(0, 2.5)\n",
    "\n",
    "        # Define initial conditions\n",
    "        #y0 = [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
    "        y0 = [0, 0]\n",
    "        # Solve the Duffing oscillator equation\n",
    "        # Local definition of the differential equation with captured parameters\n",
    "        \n",
    "        def duffing(y, t, a=a, b=b, d=d, gamma=gamma, omega=omega):\n",
    "            x, x_dot = y\n",
    "            d2x_dt2 = -d * x_dot - a * x - b * x**3 + gamma * np.cos(omega * t)\n",
    "            return [x_dot, d2x_dt2]\n",
    "\n",
    "        sol = odeint(duffing, y0, x_np, args=(a, b, d, gamma, omega))\n",
    "        x_t = sol[:, 0]  # Solution x(t)\n",
    "\n",
    "        # Store initial and final states with corresponding time points and parameters\n",
    "        #boundary_values.append([x_np[0], x_t[0], a, b, d, gamma, omega])  # Initial state\n",
    "        #boundary_values.append([x_np[-1], x_t[-1], a, b, d, gamma, omega])  # Final state\n",
    "        \n",
    "        # Compile the parameters and outputs to form the dataset\n",
    "        for xi, xti in zip(x_np, x_t):\n",
    "            data.append([xi, a, b, d, gamma, omega, xti])\n",
    "            \n",
    "        \n",
    "    return np.array(data)#, np.array(boundary_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b238a5-39ff-45e7-82ae-8b5a147eb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, boundary_values = generate_data_with_boundaries(num_samples=10000, x=np.linspace(0, 10, 500))\n",
    "data= generate_data_with_boundaries(num_samples=6000, x=np.linspace(0, 1, 500))\n",
    "# Convert the generated data to PyTorch tensors\n",
    "X = torch.tensor(data[:, :-1], dtype=torch.float32)  # Input features: [x_i, a, b, d, gamma, omega]\n",
    "Y = torch.tensor(data[:, -1], dtype=torch.float32).view(-1, 1)  # Targets: x(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b77eb9f-973c-4331-a906-649fef154fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data generation and conversion to tensors has been done as previously described\n",
    "X_tensor = torch.tensor(data[:, :-1], dtype=torch.float32)#.requires_grad_(True)  # Features: [x_i, a, b, d, gamma, omega]\n",
    "Y_tensor = torch.tensor(data[:, -1], dtype=torch.float32).view(-1, 1)  # Targets: x(t_i)\n",
    "# Set up the boundary conditions\n",
    "X_BOUNDARY = [0.0]  # boundary condition coordinate\n",
    "F_BOUNDARY = [0.0]  # boundary condition value\n",
    "#print(boundary_values.shape)  # Should output torch.Size([50000, 6])\n",
    "# Assuming boundary_values now includes the time points\n",
    "#x_boundary_tensor = torch.tensor(boundary_values[:, 0], dtype=torch.float32).requires_grad_(True)  # Time points of boundary conditions\n",
    "#f_boundary_tensor = torch.tensor(boundary_values[:, 1], dtype=torch.float32)  # Corresponding boundary states\n",
    "#boundary_conditions_tensor = torch.tensor(boundary_values, dtype = torch.float32)\n",
    "x_boundary = torch.tensor([X_BOUNDARY]).requires_grad_(True)\n",
    "f_boundary = torch.tensor([F_BOUNDARY]).requires_grad_(True)\n",
    "# Assuming boundary_conditions is prepared alongside data and targets\n",
    "#oscillation_dataset = OscillationDataset(X_tensor, Y_tensor, boundary_conditions_tensor)\n",
    "\n",
    "# Assuming boundary_conditions is prepared alongside data and targets\n",
    "oscillation_dataset = OscillationDataset(X_tensor, Y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4cb61a3-5b07-4549-93ee-63985d230fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def custom_collate(batch):\n",
    "    #data, targets, boundary_conditions = zip(*batch)\n",
    "    # Assuming data and targets are already tensors and have the same size\n",
    "    # You might need to convert them to tensors if they are not\n",
    "    #data = torch.stack(data)\n",
    "    #targets = torch.stack(targets)\n",
    "    # Handling boundary_conditions with varying sizes\n",
    "    # Example: padding boundary_conditions to the longest one in the batch\n",
    "    #boundary_conditions = pad_sequence(boundary_conditions, batch_first=True, padding_value=0)\n",
    "   # return data, targets, boundary_conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda4e872-105f-4fe4-9ff2-adf710589df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming boundary_conditions is prepared alongside data and targets\n",
    "oscillation_dataset = OscillationDataset(X_tensor, Y_tensor)#, boundary_conditions_tensor\n",
    "\n",
    "\n",
    "oscillation_dataloader = DataLoader(oscillation_dataset, batch_size=128, shuffle=True, num_workers=4)#, collate_fn=custom_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863cc0ae-c678-4398-9a5d-8eb154c2541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a class to create a fully connected neural network\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(N_INPUT, N_HIDDEN),\n",
    "            activation()\n",
    "        )\n",
    "        self.fch = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                activation()\n",
    "            ) for _ in range(N_LAYERS-1)]\n",
    "        )\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "        # Assuming your linear layer is named `layer`\n",
    "        input_size = self.fce.in_features\n",
    "        # print(\"Input size of the linear layer: \", input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2713eed9-6330-4d08-9bac-d70fce5f17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT = 6 # [x_i, a, b, d, gamma, omega]\n",
    "N_HIDDEN = 64\n",
    "N_OUTPUT = 1  # x(t)\n",
    "N_LAYERS = 6\n",
    "epochs = 6000\n",
    "model = FCN(N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model = model.to(device)\n",
    "tensor_list = [X_tensor, Y_tensor, x_boundary, f_boundary]  # Your tensors\n",
    "tensor_list = [t.to(device) for t in tensor_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a364b9-edfd-4b05-965a-42d530ba789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.001\n",
    "num_warmup_steps = 10\n",
    "num_total_steps = 6000\n",
    "decay_rate = 0.1\n",
    "decay_steps = 100\n",
    "\n",
    "def lr_lambda(current_step: int):\n",
    "    if current_step < num_warmup_steps:\n",
    "        # Linear warmup\n",
    "        return float(current_step) / float(max(1, num_warmup_steps))\n",
    "    else:\n",
    "        # Exponential decay\n",
    "        return decay_rate ** ((current_step - num_warmup_steps) // decay_steps)\n",
    "\n",
    "# Define the scheduler\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ded00e1b-1f73-4eb8-ae11-e84ef6d39573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedLoss(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, yhp, data, d, a, b, gamma, omega):\n",
    "        # Forward pass computations\n",
    "        ctx.save_for_backward(data, d, a, b, gamma, omega, yhp)\n",
    "        # Loss computation\n",
    "        return loss_physics\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Retrieve saved tensors\n",
    "        data, d, a, b, gamma, omega, yhp = ctx.saved_tensors\n",
    "        \n",
    "        # Example gradient computations (conceptual and simplified)\n",
    "        # These would need to be replaced with the actual gradients based on your loss function\n",
    "        grad_yhp = torch.autograd.grad(physics_loss, yhp, grad_outputs=grad_output, create_graph=True)[0]\n",
    "        grad_data = torch.autograd.grad(physics_loss, data, grad_outputs=grad_output, create_graph=True)[0]\n",
    "\n",
    "        # Assume gradients w.r.t. other parameters are not required\n",
    "        return grad_yhp, grad_data, None, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc372d0e-57a4-4793-9358-0f30fb98976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_idx, (sample, targets) in enumerate(oscillation_dataloader):#, batch_boundary_conditions\n",
    "        optimizer.zero_grad()\n",
    "         # Set requires_grad to True for data\n",
    "        sample.requires_grad_(True)\n",
    "        data = sample.to(device)\n",
    "        \n",
    "        targets = targets.to(device)\n",
    "        # Model prediction for the full dataset\n",
    "        yh = model(data)\n",
    "            # Data loss (comparing model output with true data)\n",
    "        y_data = Y_tensor  # True output values from your dataset\n",
    "        loss_data = torch.mean((yh - targets)**2)\n",
    "        \n",
    "        # Extract domain (time) and parameters from X_tensor\n",
    "        x_domain = data[:, 0].view(-1, 1).requires_grad_(True)\n",
    "        params = data[:, 1:]  # Parameters: a, b, d, gamma, omega\n",
    "        params = params.to(device)\n",
    "        a, b, d, gamma, omega = params.t()  # Transpose for convenience in calculations\n",
    "    \n",
    "        yhp = model(data)\n",
    "        dy_pred = torch.autograd.grad(yhp, data, torch.ones_like(yhp), create_graph=True)[0]\n",
    "        d2y_pred = torch.autograd.grad(dy_pred, data, torch.ones_like(dy_pred), create_graph=True)[0]\n",
    "\n",
    "        physics_loss = d2y_pred + d.unsqueeze(1) * dy_pred + a.unsqueeze(1) * yhp + b.unsqueeze(1) * torch.pow(yhp, 3) - gamma.unsqueeze(1) * torch.cos(omega.unsqueeze(1) * data)\n",
    "        loss_physics = (1e-4) * torch.mean(torch.square(physics_loss))\n",
    "\n",
    "        \n",
    "        \n",
    "        #x_boundary, f_boundary = boundary_conditions[:, :1], batch_boundary_conditions[:, 1:]\n",
    "        #boundary_predictions = model(x_boundary)\n",
    "        #loss_boundary =  (1e-6) *torch.mean(torch.square(boundary_predictions - f_boundary))\n",
    "        ## Compute the boundary loss by enforcing the boundary conditions\n",
    "       \n",
    "        x_boundary = torch.tensor([X_BOUNDARY]).requires_grad_(True)\n",
    "        x_boundary =  x_boundary.repeat(params.size(0),1)\n",
    "        x_boundary = x_boundary.to(device)\n",
    "        x_boundary = torch.cat([x_boundary,params],dim=1)\n",
    "        f_boundary = torch.tensor([F_BOUNDARY]).requires_grad_(True)\n",
    "        f_boundary = f_boundary.to(device)\n",
    "        yh_boundary = model(x_boundary)\n",
    "        boundary = yh_boundary - f_boundary\n",
    "        loss_boundary = (1e-6) * torch.mean(boundary**2)\n",
    "    \n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = loss_physics + loss_data + loss_boundary \n",
    "    \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch}, Total Loss: {total_loss.item()}')\n",
    "\n",
    "    if  epoch % 10 == 0:\n",
    "        model_save_path = \"/home/leo/devel/thesis/rnn_pinnthesis/fcn_pinn_1sec_param_model.pth\"\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "            \n",
    "    if  total_loss < 1e-7:\n",
    "        model_save_path = \"/home/leo/devel/thesis/rnn_pinnthesis/fcn_pinn_10sec_param_model.pth\"\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0971cb-6fa1-4087-9f1a-bd666d522c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "        plot_result(x=X_tensor[:, 0],  # Domain (time points)\n",
    "                    y_tensor_squeezed=Y_tensor,  # Ground truth data\n",
    "                    x_data=X_tensor[:, 0],  # Same as domain for plotting\n",
    "                    y_data=Y_tensor,  # Ground truth data for scatter plot\n",
    "                    yh= yh,  # Model predictions\n",
    "                    xp=None,  # Additional physics-based prediction points, if applicable\n",
    "                    physics_params=None,  # Physics parameters, if needed for additional predictions\n",
    "                    model= yhp)  # Model, if additional physics-based predictions are to be plotted    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b307d-e97d-4991-96f7-d63db0aec604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
